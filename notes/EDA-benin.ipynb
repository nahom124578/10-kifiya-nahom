{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) analysis for Benin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data quality check \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def data_quality_check(df):\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "    # Check for incorrect entries (e.g., negative values in columns where only positives should exist)\n",
    "    columns_to_check = ['GHI', 'DNI', 'DHI', 'WS', 'WSgust', 'ModA', 'ModB']\n",
    "    \n",
    "    # Identify negative values in the columns where only positive values should exist\n",
    "    incorrect_entries = {}\n",
    "    for column in columns_to_check:\n",
    "        incorrect_entries[column] = df[df[column] < 0][column].count()\n",
    "        \n",
    "    print(\"\\nIncorrect Entries (Negative Values in Columns where only Positive Expected):\")\n",
    "    for column, count in incorrect_entries.items():\n",
    "        print(f\"{column}: {count} rows with negative values\")\n",
    "    \n",
    "    # Boxplot visualization of potential outliers for sensor readings and wind data\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.boxplot(data=df[columns_to_check])\n",
    "    plt.title(\"Boxplot of Columns (GHI, DNI, DHI, WS, WSgust, ModA, ModB)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "        \n",
    "    # Visualize Distribution with Histograms for better understanding\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    df[columns_to_check].hist(bins=20, edgecolor='black', figsize=(14, 8))\n",
    "    plt.suptitle('Histograms of Columns (GHI, DNI, DHI, WS, WSgust, ModA, ModB)')\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    \n",
    "    # Perform Data Quality Check\n",
    "    data_quality_check(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_data(df):\n",
    "    # Convert 'date' column to datetime if it exists\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    # Fill missing values with the median for numeric columns to handle missing values \n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "    # Columns to check for invalid (negative) values\n",
    "    columns_to_check = ['GHI', 'DNI', 'DHI', 'WS', 'WSgust', 'ModA', 'ModB']\n",
    "    \n",
    "    # Replace negative values in these columns with NaN\n",
    "    for column in columns_to_check:\n",
    "        if column in df.columns: \n",
    "            df[column] = df[column].apply(lambda x: x if pd.notnull(x) and x >= 0 else np.nan)\n",
    "\n",
    "    # Drop irrelevant or problematic columns\n",
    "    df = df.drop(columns=['Timestamp'], errors='ignore')  # Safely drop if 'Timestamp' exists\n",
    "\n",
    "    # Select only numeric columns for further analysis\n",
    "    df_numeric = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "    return df, df_numeric\n",
    "\n",
    "def calculate_summary_statistics(df_numeric):\n",
    "    \n",
    "    # Calculate basic statistics using describe()\n",
    "    summary_stats = df_numeric.describe().T  # Transpose for better readability\n",
    "    \n",
    "    # Add additional statistics\n",
    "    summary_stats['median'] = df_numeric.median()  # Median\n",
    "    summary_stats['variance'] = df_numeric.var()  # Variance\n",
    "    summary_stats['skewness'] = df_numeric.skew()  # Skewness\n",
    "    summary_stats['kurtosis'] = df_numeric.kurt()  # Kurtosis\n",
    "\n",
    "    return summary_stats\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file '../assets/data/benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Clean the data\n",
    "    df_cleaned, df_numeric = clean_data(df)\n",
    "\n",
    "    # Check if numeric columns are present\n",
    "    if not df_numeric.empty:\n",
    "        # Calculate and display the summary statistics\n",
    "        summary = calculate_summary_statistics(df_numeric)\n",
    "        print(summary)\n",
    "\n",
    "        # Optionally, save the summary statistics to a file\n",
    "        summary.to_csv('../assets/EDA-result/summary_statistics_benin.csv', index=True)\n",
    "    else:\n",
    "        print(\"No numeric columns found in the dataset for statistical analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def preprocess_time_series(df):\n",
    "        \n",
    "    # Ensure 'Timestamp' column is in datetime format\n",
    "    if 'Timestamp' in df.columns:\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    else:\n",
    "        raise KeyError(\"The DataFrame must contain a 'Timestamp' column.\")\n",
    "    \n",
    "    # Extract useful time-based features\n",
    "    df['date'] = df['Timestamp'].dt.date  # Extract date\n",
    "    df['month'] = df['Timestamp'].dt.month  # Extract month\n",
    "    df['hour'] = df['Timestamp'].dt.hour  # Extract hour\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Plots time series data for the specified columns grouped by a time-based feature.\n",
    "def plot_time_series(df, group_by, columns, plot_type=\"line\"):\n",
    "    # Group data by the specified feature and calculate mean\n",
    "    grouped = df.groupby(group_by)[columns].mean()\n",
    "\n",
    "    # Create subplots for each column\n",
    "    num_columns = len(columns)\n",
    "    fig, axes = plt.subplots(num_columns, 1, figsize=(10, 5 * num_columns), sharex=True)\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i] if num_columns > 1 else axes\n",
    "        if plot_type == \"line\":\n",
    "            grouped[column].plot(ax=ax, kind=\"line\", marker='o', title=f\"{column} over {group_by.capitalize()}\")\n",
    "        elif plot_type == \"bar\":\n",
    "            grouped[column].plot(ax=ax, kind=\"bar\", title=f\"{column} over {group_by.capitalize()}\")\n",
    "        ax.set_ylabel(column)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main script for execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file '../assets/data/benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Preprocess the data for time series analysis\n",
    "    try:\n",
    "        df = preprocess_time_series(df)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        exit()\n",
    "\n",
    "    # Ensure the features are added correctly\n",
    "    print(\"Columns after preprocessing:\", df.columns)\n",
    "    print(df[['Timestamp', 'date', 'month', 'hour']].head())\n",
    "\n",
    "    # Columns to analyze\n",
    "    columns_to_analyze = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
    "\n",
    "    # Filter columns to ensure they exist in the dataset\n",
    "    columns_to_analyze = [col for col in columns_to_analyze if col in df.columns]\n",
    "\n",
    "    if not columns_to_analyze:\n",
    "        print(\"No columns available for analysis.\")\n",
    "        exit()\n",
    "\n",
    "    # Plot line charts grouped by month\n",
    "    print(\"Plotting trends by month:\")\n",
    "    plot_time_series(df, group_by=\"month\", columns=columns_to_analyze, plot_type=\"line\")\n",
    "\n",
    "    # Plot bar charts grouped by hour of the day\n",
    "    print(\"Plotting trends by hour of the day:\")\n",
    "    plot_time_series(df, group_by=\"hour\", columns=columns_to_analyze, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning impact \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Evaluates the impact of cleaning on sensor readings.\n",
    "def evaluate_cleaning_impact(df, cleaning_col='Cleaning', sensors=['ModA', 'ModB'], timestamp_col='Timestamp'):\n",
    "    # Ensure timestamp is in datetime format\n",
    "    if timestamp_col in df.columns:\n",
    "        df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors='coerce')\n",
    "    else:\n",
    "        raise KeyError(f\"The DataFrame must contain a '{timestamp_col}' column.\")\n",
    "\n",
    "    if cleaning_col not in df.columns:\n",
    "        raise KeyError(f\"The DataFrame must contain a '{cleaning_col}' column.\")\n",
    "    \n",
    "    # Filter data with valid timestamps and sort by timestamp\n",
    "    df = df.dropna(subset=[timestamp_col]).sort_values(by=timestamp_col)\n",
    "    \n",
    "    # Separate data before and after cleaning events\n",
    "    df['Cleaning_Event'] = (df[cleaning_col] == 1).astype(int)\n",
    "    df['Cleaning_Cumulative'] = df['Cleaning_Event'].cumsum()  # Cumulative count of cleaning events\n",
    "\n",
    "    # Group data by cleaning events\n",
    "    grouped = df.groupby('Cleaning_Cumulative')[sensors].mean()\n",
    "\n",
    "    # Plot sensor readings before and after cleaning events\n",
    "    fig, axes = plt.subplots(len(sensors), 1, figsize=(12, 6 * len(sensors)), sharex=True)\n",
    "    for i, sensor in enumerate(sensors):\n",
    "        ax = axes[i] if len(sensors) > 1 else axes\n",
    "        sns.lineplot(data=df, x=timestamp_col, y=sensor, hue='Cleaning_Cumulative', ax=ax)\n",
    "        ax.set_title(f\"Impact of Cleaning on {sensor}\")\n",
    "        ax.set_ylabel(sensor)\n",
    "        ax.set_xlabel(\"Timestamp\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary statistics by cleaning group\n",
    "    print(\"\\nSummary Statistics of Sensor Readings by Cleaning Events:\")\n",
    "    print(grouped)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file '../assets/data/benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Evaluate the impact of cleaning on ModA and ModB\n",
    "    try:\n",
    "        evaluate_cleaning_impact(df, cleaning_col='Cleaning', sensors=['ModA', 'ModB'], timestamp_col='Timestamp')\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation analysis \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Performs correlation analysis on solar radiation, temperature, and wind conditions.\n",
    "def correlation_analysis(df, radiation_cols=['GHI', 'DNI', 'DHI'], temperature_cols=['TModA', 'TModB'], wind_cols=['WS', 'WSgust', 'WD']):\n",
    "\n",
    "    # Check if columns exist in the DataFrame\n",
    "    all_columns = radiation_cols + temperature_cols + wind_cols\n",
    "    missing_columns = [col for col in all_columns if col not in df.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        print(f\"Warning: The following columns are missing: {missing_columns}\")\n",
    "    \n",
    "    #  Correlation Matrix for Solar Radiation and Temperature\n",
    "    correlation_data = df[radiation_cols + temperature_cols].corr()\n",
    "\n",
    "    # Plot the correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "    plt.title(\"Correlation Matrix: Solar Radiation and Temperature\")\n",
    "    plt.show()\n",
    "\n",
    "    #  Pair Plot for Solar Radiation and Temperature\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.pairplot(df[radiation_cols + temperature_cols], kind='scatter', diag_kind='kde', markers='o')\n",
    "    plt.suptitle(\"Pair Plot: Solar Radiation and Temperature\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter Matrix for Wind Conditions vs. Solar Irradiance\n",
    "    wind_radiation_data = df[wind_cols + radiation_cols]\n",
    "    \n",
    "    # Plot the scatter matrix\n",
    "    sns.pairplot(wind_radiation_data, kind='scatter', diag_kind='kde', markers='o', hue=None)\n",
    "    plt.suptitle(\"Scatter Matrix: Wind Conditions and Solar Irradiance\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Perform the correlation analysis\n",
    "    correlation_analysis(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind analysis \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from windrose import WindroseAxes\n",
    "\n",
    "# Plots a wind rose showing the distribution of wind speed and direction.\n",
    "def plot_wind_rose(df, wind_speed_col='WS', wind_direction_col='WD'):\n",
    "    \n",
    "    # Ensure wind speed and direction columns exist\n",
    "    if wind_speed_col not in df.columns or wind_direction_col not in df.columns:\n",
    "        raise KeyError(f\"The DataFrame must contain columns '{wind_speed_col}' and '{wind_direction_col}'.\")\n",
    "\n",
    "    # Prepare data for the wind rose plot\n",
    "    wind_speed = df[wind_speed_col].dropna()\n",
    "    wind_direction = df[wind_direction_col].dropna()\n",
    "\n",
    "    # Initialize the wind rose axes\n",
    "    ax = WindroseAxes.from_ax()\n",
    "\n",
    "    # Create the wind rose plot\n",
    "    ax.bar(wind_direction, wind_speed, bins=np.arange(0, 360, 45), normed=True, opening=0.8, edgecolor='black')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_title(\"Wind Rose - Wind Speed and Direction Distribution\")\n",
    "    ax.set_legend(title=\"Wind Speed (m/s)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Creates a radial bar plot showing the distribution of wind speed and direction.\n",
    "def plot_radial_bar(df, wind_speed_col='WS', wind_direction_col='WD'):\n",
    "    # Ensure the columns exist in the DataFrame\n",
    "    if wind_speed_col not in df.columns or wind_direction_col not in df.columns:\n",
    "        raise KeyError(f\"The DataFrame must contain columns '{wind_speed_col}' and '{wind_direction_col}'.\")\n",
    "\n",
    "    # Prepare wind speed and direction data, dropping rows where either is missing\n",
    "    df_clean = df.dropna(subset=[wind_speed_col, wind_direction_col])\n",
    "\n",
    "    # Ensure there is data after cleaning\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(\"No valid data available for plotting.\")\n",
    "\n",
    "    wind_speed = df_clean[wind_speed_col]\n",
    "    wind_direction = df_clean[wind_direction_col]\n",
    "\n",
    "    # Convert wind direction to radians\n",
    "    wind_direction_rad = np.deg2rad(wind_direction)\n",
    "\n",
    "    # Create a radial bar plot\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(8, 8))\n",
    "\n",
    "    # Plot data as bars on the polar plot (wind speed vs. wind direction)\n",
    "    ax.bar(wind_direction_rad, wind_speed, width=0.3, edgecolor='black', alpha=0.7)\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_title(\"Radial Bar Plot: Wind Speed and Direction\")\n",
    "    ax.set_xlabel(\"Wind Direction\")\n",
    "    ax.set_ylabel(\"Wind Speed (m/s)\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Plot Wind Rose\n",
    "    plot_wind_rose(df, wind_speed_col='WS', wind_direction_col='WD')\n",
    "\n",
    "    # Plot Radial Bar Plot\n",
    "    plot_radial_bar(df, wind_speed_col='WS', wind_direction_col='WD')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature analysis \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plots a scatter plot to visualize the relationship between two variables.\n",
    "def plot_scatter(df, x_col, y_col, title, xlabel, ylabel):\n",
    "   \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df[x_col], df[y_col], alpha=0.6, edgecolors='w', s=100)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#  Plots a pairplot to analyze the relationships and correlations between variables.\n",
    "def plot_pairplot(df, columns, title=\"Correlation Analysis\"):\n",
    "    \n",
    "    sns.pairplot(df[columns], height=2.5)\n",
    "    plt.suptitle(title, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Calculates and visualizes the correlation matrix for selected columns.\n",
    "def correlation_matrix(df, columns):\n",
    "    \n",
    "    corr_matrix = df[columns].corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Check if required columns are present in the DataFrame\n",
    "    required_columns = ['RH', 'TModA', 'TModB', 'GHI', 'DNI', 'DHI']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(\"Error: Missing one or more required columns.\")\n",
    "        exit()\n",
    "\n",
    "    # 1. Scatter plot: Temperature vs. Relative Humidity (TModA vs RH)\n",
    "    plot_scatter(df, 'RH', 'TModA', 'Temperature vs. Relative Humidity (TModA)', 'Relative Humidity (%)', 'Temperature (°C)')\n",
    "\n",
    "    # 2. Scatter plot: Solar Radiation vs. Relative Humidity (GHI vs RH)\n",
    "    plot_scatter(df, 'RH', 'GHI', 'Solar Radiation vs. Relative Humidity (GHI)', 'Relative Humidity (%)', 'Global Horizontal Irradiance (W/m²)')\n",
    "\n",
    "    # 3. Pairplot to visualize correlations between RH, TModA, TModB, GHI, DNI, DHI\n",
    "    plot_pairplot(df, ['RH', 'TModA', 'TModB', 'GHI', 'DNI', 'DHI'], \"Temperature and Solar Radiation Analysis\")\n",
    "\n",
    "    # 4. Correlation Matrix: RH, TModA, TModB, GHI, DNI, DHI\n",
    "    correlation_matrix(df, ['RH', 'TModA', 'TModB', 'GHI', 'DNI', 'DHI'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#  Plots histograms for the specified columns to visualize their frequency distribution.\n",
    "def plot_histograms(df, columns, bins=20, title=\"Histogram Analysis\"):\n",
    "    \n",
    "    # Create subplots for each column\n",
    "    num_columns = len(columns)\n",
    "    fig, axes = plt.subplots(num_columns, 1, figsize=(10, 5 * num_columns))\n",
    "    \n",
    "    if num_columns == 1:\n",
    "        axes = [axes]  # Make sure axes is iterable if only one column\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i]\n",
    "        sns.histplot(df[column], bins=bins, kde=True, ax=ax, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f'{column} Distribution')\n",
    "        ax.set_xlabel(column)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Check if required columns are present in the DataFrame\n",
    "    required_columns = ['GHI', 'DNI', 'DHI', 'WS', 'TModA', 'TModB']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(\"Error: Missing one or more required columns.\")\n",
    "        exit()\n",
    "\n",
    "    # List of columns to analyze for histograms\n",
    "    columns_to_analyze = ['GHI', 'DNI', 'DHI', 'WS', 'TModA', 'TModB']\n",
    "\n",
    "    # Plot histograms for the specified columns\n",
    "    plot_histograms(df, columns_to_analyze, bins=20, title=\"Distribution of Solar and Temperature Variables\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z score analysis \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate Z-scores for the specified columns in the DataFrame.\n",
    "def calculate_z_scores(df, columns):\n",
    "    \n",
    "    df_z_scores = df[columns].apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    return df_z_scores\n",
    "\n",
    "\n",
    "# Flag data points where the absolute Z-score exceeds the specified threshold.\n",
    "def flag_outliers(df_z_scores, threshold=3):\n",
    "   \n",
    "    df_outliers = df_z_scores.abs() > threshold\n",
    "    return df_outliers\n",
    "\n",
    "#  Plot histograms of Z-scores to visualize the distribution and outliers.\n",
    "def plot_z_scores(df_z_scores, columns):\n",
    "    \n",
    "    num_columns = len(columns)\n",
    "    fig, axes = plt.subplots(num_columns, 1, figsize=(10, 5 * num_columns))\n",
    "    \n",
    "    if num_columns == 1:\n",
    "        axes = [axes]  # Make sure axes is iterable if only one column\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i]\n",
    "        df_z_scores[column].plot(kind=\"hist\", bins=30, ax=ax, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        ax.set_title(f'{column} Z-Score Distribution')\n",
    "        ax.set_xlabel('Z-Score')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Check if required columns are present in the DataFrame\n",
    "    required_columns = ['GHI', 'DNI', 'DHI', 'WS', 'TModA', 'TModB']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(\"Error: Missing one or more required columns.\")\n",
    "        exit()\n",
    "\n",
    "    # List of columns to analyze for Z-scores\n",
    "    columns_to_analyze = ['GHI', 'DNI', 'DHI', 'WS', 'TModA', 'TModB']\n",
    "\n",
    "    # Calculate Z-scores for the specified columns\n",
    "    df_z_scores = calculate_z_scores(df, columns_to_analyze)\n",
    "\n",
    "    # Flag outliers based on Z-score threshold (default is 3)\n",
    "    df_outliers = flag_outliers(df_z_scores, threshold=3)\n",
    "\n",
    "    # Display the flagged outliers\n",
    "    print(\"Flagged Outliers (True indicates outlier):\")\n",
    "    print(df_outliers)\n",
    "\n",
    "    # Plot histograms of Z-scores to visualize the distribution\n",
    "    plot_z_scores(df_z_scores, columns_to_analyze)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  bubble charts \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plots a bubble chart for the given columns in the DataFrame.\n",
    "def plot_bubble_chart(df, x_column, y_column, size_column, color_column=None, title=\"Bubble Chart\"):\n",
    "\n",
    "    # Ensure the required columns are present\n",
    "    required_columns = [x_column, y_column, size_column]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(f\"Error: Missing one or more required columns: {required_columns}\")\n",
    "        return\n",
    "\n",
    "    # Define the bubble size (we can scale the size for better visibility)\n",
    "    size = df[size_column] * 10  # Scale the size for visibility, you can adjust the factor as needed\n",
    "    if color_column and color_column in df.columns:\n",
    "        color = df[color_column]\n",
    "    else:\n",
    "        color = 'blue'  # Default to blue if no color column is provided\n",
    "\n",
    "    # Create the bubble chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(x=df[x_column], y=df[y_column], s=size, c=color, alpha=0.5, cmap='viridis', edgecolors=\"w\", linewidth=0.5)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "\n",
    "    # If a color column is specified, add a color bar\n",
    "    if color_column:\n",
    "        plt.colorbar(scatter, label=color_column)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Check if required columns are present in the DataFrame\n",
    "    required_columns = ['GHI', 'Tamb', 'WS', 'RH']  # Modify if using BP instead of RH\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(f\"Error: Missing one or more required columns: {required_columns}\")\n",
    "        exit()\n",
    "\n",
    "    # Plot bubble chart with GHI vs Tamb vs WS, and RH as bubble size\n",
    "    plot_bubble_chart(df, x_column='GHI', y_column='Tamb', size_column='RH', color_column='WS', title=\"GHI vs Tamb vs WS with RH as Bubble Size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  data cleaning \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Clean the dataset by handling missing values, anomalies, and irrelevant columns.\n",
    "def clean_data(df):\n",
    "    \n",
    "    #  Drop columns that are entirely null (e.g., 'Comments')\n",
    "    df = df.dropna(axis=1, how='all')  # Drop columns where all values are NaN\n",
    "    \n",
    "    #  Handle missing values in the remaining columns\n",
    "    # Fill missing numerical columns with median, and categorical columns with mode\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':  # Categorical data\n",
    "            df[column] = df[column].fillna(df[column].mode()[0])  # Fill with mode\n",
    "        else:  # Numerical data\n",
    "            df[column] = df[column].fillna(df[column].median())  # Fill with median\n",
    "    \n",
    "    # Handle anomalies in numerical columns (e.g., negative values where they shouldn't be)\n",
    "    # Define the columns where you expect non-negative values\n",
    "    columns_to_check = ['GHI', 'DNI', 'DHI', 'WS', 'WSgust', 'TModA', 'TModB']\n",
    "    \n",
    "    # Replace negative values in these columns with NaN (or you can choose to drop them if needed)\n",
    "    for column in columns_to_check:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].apply(lambda x: x if x >= 0 else np.nan)\n",
    "    \n",
    "    # Drop rows with NaN after anomaly correction (optional, depending on dataset size)\n",
    "    df = df.dropna(how='any')  # Drop rows where any column has NaN (optional based on dataset size)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset \n",
    "    try:\n",
    "        df = pd.read_csv('../assets/data/benin-malanville.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: The file 'benin-malanville.csv' was not found.\")\n",
    "        exit()\n",
    "\n",
    "    # Clean the data\n",
    "    df_cleaned = clean_data(df)\n",
    "\n",
    "    # Display the cleaned data (or save it to a new file)\n",
    "    print(df_cleaned.head())\n",
    "\n",
    "    # Optionally, save the cleaned dataset to a new file\n",
    "    df_cleaned.to_csv('../assets/EDA-result/cleaned_benin_malanville.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
